{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/decathlon_data\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/share/decathlon-1.0-data.tar.gz -O /content/decathlon_data/decathlon-1.0-data.tar.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjtsDL-olKzh",
        "outputId": "ad2eea8a-1704-4c0f-a8c1-66b88917cdb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-13 16:14:48--  http://www.robots.ox.ac.uk/~vgg/share/decathlon-1.0-data.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.robots.ox.ac.uk/~vgg/share/decathlon-1.0-data.tar.gz [following]\n",
            "--2024-11-13 16:14:48--  https://www.robots.ox.ac.uk/~vgg/share/decathlon-1.0-data.tar.gz\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 406351554 (388M) [application/x-gzip]\n",
            "Saving to: ‘/content/decathlon_data/decathlon-1.0-data.tar.gz’\n",
            "\n",
            "/content/decathlon_ 100%[===================>] 387.53M  21.3MB/s    in 20s     \n",
            "\n",
            "2024-11-13 16:15:09 (19.7 MB/s) - ‘/content/decathlon_data/decathlon-1.0-data.tar.gz’ saved [406351554/406351554]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "with tarfile.open('/content/decathlon_data/decathlon-1.0-data.tar.gz') as tar:\n",
        "    tar.extractall(path='/content/decathlon_data')\n"
      ],
      "metadata": {
        "id": "1Mt12tHkm9Uj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with tarfile.open('/content/decathlon_data/aircraft.tar') as tar:\n",
        "    tar.extractall(path='/content/decathlon_data/')\n"
      ],
      "metadata": {
        "id": "Z0WUq9Rent_f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import necessary libraries and set up device\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Set up device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60XczHZ2xcZg",
        "outputId": "297af35b-b13e-4f7b-a12f-e6f575ebcc69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dir = '/content/decathlon_data/aircraft/train'\n",
        "val_dir = '/content/decathlon_data/aircraft/val'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "1AIlySdFn83h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# resnet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# final fc layer\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to('cuda')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAK7IxVeotPP",
        "outputId": "5b060c56-78ef-4084-87a3-258fddb087a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 191MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "num_epochs = 20  # 150\n",
        "initial_lr = 0.001\n",
        "milestones = [5, 10, 15]\n",
        "gamma = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=initial_lr, momentum=0.9)\n",
        "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "QjmqM1b9pXVT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.cuda.amp as amp\n",
        "scaler = amp.GradScaler()  # mixed-precision scaler\n",
        "\n",
        "# Cell 3: Training and validation functions\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():  # Mixed precision\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch} - Training loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "def validate():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy}%\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOhQENZoptpI",
        "outputId": "9cccb633-2146-4a1b-9b6f-f6b5bd654c95"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-42204bd81e0f>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler()  # mixed-precision scaler\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Training loop with learning rate drops\n",
        "best_accuracy = 0\n",
        "for epoch in range(num_epochs):\n",
        "    train_one_epoch(epoch)\n",
        "    accuracy = validate()\n",
        "    scheduler.step()  # Adjust learning rate as per the schedule\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), \"best_finetuned_model.pth\")  # Save best model\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} completed. Best Accuracy so far: {best_accuracy}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_3s8QFaxCDc",
        "outputId": "f9d368ba-193e-4854-9b52-46da8bac7461"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-42204bd81e0f>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training loss: 4.615468726967865\n",
            "Validation Accuracy: 2.43024302430243%\n",
            "Epoch 1/20 completed. Best Accuracy so far: 2.43024302430243%\n",
            "Epoch 1 - Training loss: 4.456771562684257\n",
            "Validation Accuracy: 5.6705670567056705%\n",
            "Epoch 2/20 completed. Best Accuracy so far: 5.6705670567056705%\n",
            "Epoch 2 - Training loss: 4.260826641658567\n",
            "Validation Accuracy: 8.4008400840084%\n",
            "Epoch 3/20 completed. Best Accuracy so far: 8.4008400840084%\n",
            "Epoch 3 - Training loss: 4.010825202150165\n",
            "Validation Accuracy: 12.211221122112212%\n",
            "Epoch 4/20 completed. Best Accuracy so far: 12.211221122112212%\n",
            "Epoch 4 - Training loss: 3.7188505991449894\n",
            "Validation Accuracy: 14.641464146414641%\n",
            "Epoch 5/20 completed. Best Accuracy so far: 14.641464146414641%\n",
            "Epoch 5 - Training loss: 3.494002382710295\n",
            "Validation Accuracy: 15.661566156615661%\n",
            "Epoch 6/20 completed. Best Accuracy so far: 15.661566156615661%\n",
            "Epoch 6 - Training loss: 3.4613864556798397\n",
            "Validation Accuracy: 15.931593159315932%\n",
            "Epoch 7/20 completed. Best Accuracy so far: 15.931593159315932%\n",
            "Epoch 7 - Training loss: 3.4242069091436997\n",
            "Validation Accuracy: 16.32163216321632%\n",
            "Epoch 8/20 completed. Best Accuracy so far: 16.32163216321632%\n",
            "Epoch 8 - Training loss: 3.3968107835301815\n",
            "Validation Accuracy: 17.13171317131713%\n",
            "Epoch 9/20 completed. Best Accuracy so far: 17.13171317131713%\n",
            "Epoch 9 - Training loss: 3.363909860826888\n",
            "Validation Accuracy: 17.76177617761776%\n",
            "Epoch 10/20 completed. Best Accuracy so far: 17.76177617761776%\n",
            "Epoch 10 - Training loss: 3.351577012044079\n",
            "Validation Accuracy: 17.671767176717672%\n",
            "Epoch 11/20 completed. Best Accuracy so far: 17.76177617761776%\n",
            "Epoch 11 - Training loss: 3.3303668409023643\n",
            "Validation Accuracy: 17.4017401740174%\n",
            "Epoch 12/20 completed. Best Accuracy so far: 17.76177617761776%\n",
            "Epoch 12 - Training loss: 3.3286257105053596\n",
            "Validation Accuracy: 17.431743174317432%\n",
            "Epoch 13/20 completed. Best Accuracy so far: 17.76177617761776%\n",
            "Epoch 13 - Training loss: 3.3340248521768823\n",
            "Validation Accuracy: 17.64176417641764%\n",
            "Epoch 14/20 completed. Best Accuracy so far: 17.76177617761776%\n",
            "Epoch 14 - Training loss: 3.3198551456883267\n",
            "Validation Accuracy: 17.791779177917793%\n",
            "Epoch 15/20 completed. Best Accuracy so far: 17.791779177917793%\n",
            "Epoch 15 - Training loss: 3.3208403092510297\n",
            "Validation Accuracy: 17.52175217521752%\n",
            "Epoch 16/20 completed. Best Accuracy so far: 17.791779177917793%\n",
            "Epoch 16 - Training loss: 3.318177493113392\n",
            "Validation Accuracy: 17.791779177917793%\n",
            "Epoch 17/20 completed. Best Accuracy so far: 17.791779177917793%\n",
            "Epoch 17 - Training loss: 3.3214211239005036\n",
            "Validation Accuracy: 18.061806180618063%\n",
            "Epoch 18/20 completed. Best Accuracy so far: 18.061806180618063%\n",
            "Epoch 18 - Training loss: 3.3247753944037095\n",
            "Validation Accuracy: 17.581758175817583%\n",
            "Epoch 19/20 completed. Best Accuracy so far: 18.061806180618063%\n",
            "Epoch 19 - Training loss: 3.3232493355589092\n",
            "Validation Accuracy: 17.64176417641764%\n",
            "Epoch 20/20 completed. Best Accuracy so far: 18.061806180618063%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new lr\n",
        "learning_rates = [0.01, 0.1]\n",
        "results = {}\n",
        "num_epochs = 20\n"
      ],
      "metadata": {
        "id": "qTI4ufcAr6kG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def reset_model():\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nStarting experiment with learning rate = {lr}\")\n",
        "    model = reset_model()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
        "\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(epoch)\n",
        "        accuracy = validate()\n",
        "        scheduler.step()\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            torch.save(model.state_dict(), f\"best_finetuned_model_lr_{lr}.pth\")\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} completed. Best Accuracy so far with LR {lr}: {best_accuracy}%\")\n",
        "\n",
        "    results[lr] = best_accuracy\n",
        "\n",
        "for lr, accuracy in results.items():\n",
        "    print(f\"Final best accuracy with learning rate {lr}: {accuracy}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPy046x8zvUc",
        "outputId": "2f20bea5-f4e0-44f9-b2fd-1ebe59e834d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting experiment with learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-42204bd81e0f>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Training loss: 4.400332806245336\n",
            "Validation Accuracy: 12.691269126912692%\n",
            "Epoch 1/20 completed. Best Accuracy so far with LR 0.01: 12.691269126912692%\n",
            "Epoch 1 - Training loss: 2.8784303620176495\n",
            "Validation Accuracy: 25.442544254425442%\n",
            "Epoch 2/20 completed. Best Accuracy so far with LR 0.01: 25.442544254425442%\n",
            "Epoch 2 - Training loss: 1.6528653153833353\n",
            "Validation Accuracy: 37.29372937293729%\n",
            "Epoch 3/20 completed. Best Accuracy so far with LR 0.01: 37.29372937293729%\n",
            "Epoch 3 - Training loss: 0.9895726667260224\n",
            "Validation Accuracy: 36.27362736273627%\n",
            "Epoch 4/20 completed. Best Accuracy so far with LR 0.01: 37.29372937293729%\n",
            "Epoch 4 - Training loss: 0.5170760329039592\n",
            "Validation Accuracy: 47.64476447644765%\n",
            "Epoch 5/20 completed. Best Accuracy so far with LR 0.01: 47.64476447644765%\n",
            "Epoch 5 - Training loss: 0.1896340951042355\n",
            "Validation Accuracy: 56.58565856585658%\n",
            "Epoch 6/20 completed. Best Accuracy so far with LR 0.01: 56.58565856585658%\n",
            "Epoch 6 - Training loss: 0.10666560550343315\n",
            "Validation Accuracy: 57.15571557155715%\n",
            "Epoch 7/20 completed. Best Accuracy so far with LR 0.01: 57.15571557155715%\n",
            "Epoch 7 - Training loss: 0.08856780686468449\n",
            "Validation Accuracy: 57.42574257425743%\n",
            "Epoch 8/20 completed. Best Accuracy so far with LR 0.01: 57.42574257425743%\n",
            "Epoch 8 - Training loss: 0.07614615194077762\n",
            "Validation Accuracy: 57.3057305730573%\n",
            "Epoch 9/20 completed. Best Accuracy so far with LR 0.01: 57.42574257425743%\n",
            "Epoch 9 - Training loss: 0.06222951890162702\n",
            "Validation Accuracy: 57.515751575157516%\n",
            "Epoch 10/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 10 - Training loss: 0.057049693223440424\n",
            "Validation Accuracy: 57.515751575157516%\n",
            "Epoch 11/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 11 - Training loss: 0.053735517105966246\n",
            "Validation Accuracy: 57.215721572157214%\n",
            "Epoch 12/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 12 - Training loss: 0.05454347310763485\n",
            "Validation Accuracy: 56.885688568856885%\n",
            "Epoch 13/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 13 - Training loss: 0.060355275025907554\n",
            "Validation Accuracy: 57.39573957395739%\n",
            "Epoch 14/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 14 - Training loss: 0.05460889257912366\n",
            "Validation Accuracy: 57.455745574557454%\n",
            "Epoch 15/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 15 - Training loss: 0.052472382362158794\n",
            "Validation Accuracy: 57.24572457245725%\n",
            "Epoch 16/20 completed. Best Accuracy so far with LR 0.01: 57.515751575157516%\n",
            "Epoch 16 - Training loss: 0.05213414329402852\n",
            "Validation Accuracy: 57.605760576057605%\n",
            "Epoch 17/20 completed. Best Accuracy so far with LR 0.01: 57.605760576057605%\n",
            "Epoch 17 - Training loss: 0.05471408437445478\n",
            "Validation Accuracy: 57.54575457545754%\n",
            "Epoch 18/20 completed. Best Accuracy so far with LR 0.01: 57.605760576057605%\n",
            "Epoch 18 - Training loss: 0.0590472880680606\n",
            "Validation Accuracy: 56.975697569756974%\n",
            "Epoch 19/20 completed. Best Accuracy so far with LR 0.01: 57.605760576057605%\n",
            "Epoch 19 - Training loss: 0.05056760340647878\n",
            "Validation Accuracy: 57.39573957395739%\n",
            "Epoch 20/20 completed. Best Accuracy so far with LR 0.01: 57.605760576057605%\n",
            "\n",
            "Starting experiment with learning rate = 0.1\n",
            "Epoch 0 - Training loss: 4.845246764848817\n",
            "Validation Accuracy: 1.2601260126012601%\n",
            "Epoch 1/20 completed. Best Accuracy so far with LR 0.1: 1.2601260126012601%\n",
            "Epoch 1 - Training loss: 4.560235725258881\n",
            "Validation Accuracy: 2.1002100210021%\n",
            "Epoch 2/20 completed. Best Accuracy so far with LR 0.1: 2.1002100210021%\n",
            "Epoch 2 - Training loss: 4.500230177393499\n",
            "Validation Accuracy: 1.3501350135013501%\n",
            "Epoch 3/20 completed. Best Accuracy so far with LR 0.1: 2.1002100210021%\n",
            "Epoch 3 - Training loss: 4.428632187393476\n",
            "Validation Accuracy: 2.6102610261026102%\n",
            "Epoch 4/20 completed. Best Accuracy so far with LR 0.1: 2.6102610261026102%\n",
            "Epoch 4 - Training loss: 4.351501140954359\n",
            "Validation Accuracy: 3.6903690369036903%\n",
            "Epoch 5/20 completed. Best Accuracy so far with LR 0.1: 3.6903690369036903%\n",
            "Epoch 5 - Training loss: 4.202538652240105\n",
            "Validation Accuracy: 4.2004200420042%\n",
            "Epoch 6/20 completed. Best Accuracy so far with LR 0.1: 4.2004200420042%\n",
            "Epoch 6 - Training loss: 4.101372619844833\n",
            "Validation Accuracy: 4.71047104710471%\n",
            "Epoch 7/20 completed. Best Accuracy so far with LR 0.1: 4.71047104710471%\n",
            "Epoch 7 - Training loss: 4.0063172331396135\n",
            "Validation Accuracy: 4.53045304530453%\n",
            "Epoch 8/20 completed. Best Accuracy so far with LR 0.1: 4.71047104710471%\n",
            "Epoch 8 - Training loss: 3.9393026603842682\n",
            "Validation Accuracy: 4.59045904590459%\n",
            "Epoch 9/20 completed. Best Accuracy so far with LR 0.1: 4.71047104710471%\n",
            "Epoch 9 - Training loss: 3.870732118498604\n",
            "Validation Accuracy: 6.0606060606060606%\n",
            "Epoch 10/20 completed. Best Accuracy so far with LR 0.1: 6.0606060606060606%\n",
            "Epoch 10 - Training loss: 3.695266350260321\n",
            "Validation Accuracy: 7.170717071707171%\n",
            "Epoch 11/20 completed. Best Accuracy so far with LR 0.1: 7.170717071707171%\n",
            "Epoch 11 - Training loss: 3.6369820855698496\n",
            "Validation Accuracy: 7.260726072607261%\n",
            "Epoch 12/20 completed. Best Accuracy so far with LR 0.1: 7.260726072607261%\n",
            "Epoch 12 - Training loss: 3.5877696343188017\n",
            "Validation Accuracy: 7.050705070507051%\n",
            "Epoch 13/20 completed. Best Accuracy so far with LR 0.1: 7.260726072607261%\n",
            "Epoch 13 - Training loss: 3.559072831891618\n",
            "Validation Accuracy: 7.650765076507651%\n",
            "Epoch 14/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 14 - Training loss: 3.5189842368071935\n",
            "Validation Accuracy: 7.650765076507651%\n",
            "Epoch 15/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 15 - Training loss: 3.4759910466536037\n",
            "Validation Accuracy: 7.650765076507651%\n",
            "Epoch 16/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 16 - Training loss: 3.4782895322115914\n",
            "Validation Accuracy: 7.320732073207321%\n",
            "Epoch 17/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 17 - Training loss: 3.4875368802052624\n",
            "Validation Accuracy: 7.590759075907591%\n",
            "Epoch 18/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 18 - Training loss: 3.4543918258738966\n",
            "Validation Accuracy: 7.620762076207621%\n",
            "Epoch 19/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Epoch 19 - Training loss: 3.459229586259374\n",
            "Validation Accuracy: 7.440744074407441%\n",
            "Epoch 20/20 completed. Best Accuracy so far with LR 0.1: 7.650765076507651%\n",
            "Final best accuracy with learning rate 0.01: 57.605760576057605%\n",
            "Final best accuracy with learning rate 0.1: 7.650765076507651%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7UVhDLI0VJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three learning rates were compared: 0.001, 0.01, and 0.1. At 0.001, the model converged steadily, achieving a best accuracy of 18.06%, indicating slow but stable learning. With 0.01, accuracy improved significantly to 57.61%, showing that a higher rate accelerated convergence and improved performance, However, with 0.1, accuracy dropped to 7.17%, likely due to excessive updates that hindered convergence. Overall, 0.01 provided the best results, balancing faster learning with stable convergence.\n"
      ],
      "metadata": {
        "id": "sxBnEeJu4o9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final fully connected layer\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Update the final fully connected layer to match the target dataset\n",
        "num_classes = len(train_dataset.classes)  # Make sure train_dataset is loaded and defined\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "PLZX9Z7r42jT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "# Training function for one epoch\n",
        "def train_one_epoch(epoch, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    print(f\"Epoch {epoch} - Training loss: {epoch_loss}\")\n",
        "\n",
        "# Validation function\n",
        "def validate(dataloader, criterion):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {accuracy}%\")\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "6W6y_Rnq527A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define initial hyperparameters\n",
        "learning_rates = [0.01, 0.001] #[0.1,0.01,0.001]\n",
        "num_epochs = 20\n",
        "milestones = [5, 10, 15]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    print(f\"\\nStarting experiment with learning rate = {lr}\")\n",
        "    optimizer = optim.SGD(model.fc.parameters(), lr=lr, momentum=0.9)\n",
        "    scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_one_epoch(epoch, train_loader, criterion, optimizer)  # Assume train_loader is defined\n",
        "        accuracy = validate(val_loader, criterion)  # Assume val_loader is defined\n",
        "\n",
        "        # Save the best model for each learning rate\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            torch.save(model.state_dict(), f\"best_feature_extractor_lr_{lr}.pth\")\n",
        "\n",
        "        scheduler.step()\n",
        "    print(f\"Best Accuracy with LR={lr}: {best_accuracy}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hkqE1mu55wz",
        "outputId": "d36d0930-0160-47f4-c7fc-1b8c01f21fbb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting experiment with learning rate = 0.01\n",
            "Epoch 0 - Training loss: 4.634102731245895\n",
            "Validation Accuracy: 5.4005400540054005%\n",
            "Epoch 1 - Training loss: 4.177594509536661\n",
            "Validation Accuracy: 7.890789078907891%\n",
            "Epoch 2 - Training loss: 3.755975847696214\n",
            "Validation Accuracy: 11.761176117611761%\n",
            "Epoch 3 - Training loss: 3.420887715386\n",
            "Validation Accuracy: 13.111311131113112%\n",
            "Epoch 4 - Training loss: 3.15342857298482\n",
            "Validation Accuracy: 13.861386138613861%\n",
            "Epoch 5 - Training loss: 2.837767365312033\n",
            "Validation Accuracy: 18.391839183918393%\n",
            "Epoch 6 - Training loss: 2.7517524832512135\n",
            "Validation Accuracy: 18.391839183918393%\n",
            "Epoch 7 - Training loss: 2.726473193720707\n",
            "Validation Accuracy: 18.6018601860186%\n",
            "Epoch 8 - Training loss: 2.7085370235122745\n",
            "Validation Accuracy: 18.57185718571857%\n",
            "Epoch 9 - Training loss: 2.6894915402829467\n",
            "Validation Accuracy: 18.511851185118513%\n",
            "Epoch 10 - Training loss: 2.65576637170239\n",
            "Validation Accuracy: 18.661866186618663%\n",
            "Epoch 11 - Training loss: 2.6497227510579275\n",
            "Validation Accuracy: 18.69186918691869%\n",
            "Epoch 12 - Training loss: 2.6511048515470854\n",
            "Validation Accuracy: 18.72187218721872%\n",
            "Epoch 13 - Training loss: 2.6465751937426845\n",
            "Validation Accuracy: 18.81188118811881%\n",
            "Epoch 14 - Training loss: 2.6419636473801584\n",
            "Validation Accuracy: 18.391839183918393%\n",
            "Epoch 15 - Training loss: 2.6458321075347917\n",
            "Validation Accuracy: 18.421842184218423%\n",
            "Epoch 16 - Training loss: 2.6482593464007547\n",
            "Validation Accuracy: 18.21182118211821%\n",
            "Epoch 17 - Training loss: 2.647386990411595\n",
            "Validation Accuracy: 18.6018601860186%\n",
            "Epoch 18 - Training loss: 2.634377986997205\n",
            "Validation Accuracy: 18.421842184218423%\n",
            "Epoch 19 - Training loss: 2.635482817977649\n",
            "Validation Accuracy: 18.421842184218423%\n",
            "Best Accuracy with LR=0.01: 18.81188118811881%\n",
            "\n",
            "Starting experiment with learning rate = 0.001\n",
            "Epoch 0 - Training loss: 2.656406985547776\n",
            "Validation Accuracy: 18.69186918691869%\n",
            "Epoch 1 - Training loss: 2.6462399905215643\n",
            "Validation Accuracy: 18.72187218721872%\n",
            "Epoch 2 - Training loss: 2.6255331062312317\n",
            "Validation Accuracy: 18.781878187818783%\n",
            "Epoch 3 - Training loss: 2.6133554242082035\n",
            "Validation Accuracy: 19.141914191419144%\n",
            "Epoch 4 - Training loss: 2.5943562279365415\n",
            "Validation Accuracy: 18.93189318931893%\n",
            "Epoch 5 - Training loss: 2.5581023102401614\n",
            "Validation Accuracy: 18.81188118811881%\n",
            "Epoch 6 - Training loss: 2.5547952250084194\n",
            "Validation Accuracy: 19.08190819081908%\n",
            "Epoch 7 - Training loss: 2.557178331551326\n",
            "Validation Accuracy: 18.631863186318633%\n",
            "Epoch 8 - Training loss: 2.5486749276903193\n",
            "Validation Accuracy: 18.72187218721872%\n",
            "Epoch 9 - Training loss: 2.546762874760024\n",
            "Validation Accuracy: 18.751875187518753%\n",
            "Epoch 10 - Training loss: 2.545011272098608\n",
            "Validation Accuracy: 18.901890189018903%\n",
            "Epoch 11 - Training loss: 2.551009082765585\n",
            "Validation Accuracy: 18.781878187818783%\n",
            "Epoch 12 - Training loss: 2.5469813667233288\n",
            "Validation Accuracy: 18.84188418841884%\n",
            "Epoch 13 - Training loss: 2.5422537564230168\n",
            "Validation Accuracy: 19.021902190219024%\n",
            "Epoch 14 - Training loss: 2.5458513687811144\n",
            "Validation Accuracy: 18.661866186618663%\n",
            "Epoch 15 - Training loss: 2.5418577438782415\n",
            "Validation Accuracy: 19.05190519051905%\n",
            "Epoch 16 - Training loss: 2.550052585041158\n",
            "Validation Accuracy: 18.661866186618663%\n",
            "Epoch 17 - Training loss: 2.545046376552708\n",
            "Validation Accuracy: 18.84188418841884%\n",
            "Epoch 18 - Training loss: 2.5437792268568837\n",
            "Validation Accuracy: 18.72187218721872%\n",
            "Epoch 19 - Training loss: 2.552525713119095\n",
            "Validation Accuracy: 19.17191719171917%\n",
            "Best Accuracy with LR=0.001: 19.17191719171917%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPEVMouW5_-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In feature extraction with a frozen ResNet50 model, learning rates of 0.1, 0.01, and 0.001 yielded distinct results in validation accuracy and training dynamics. Learning rate 0.1 achieved the highest validation accuracy at 19.53%, though training loss fluctuated. Learning rate 0.01 reached a peak accuracy of 18.81% with more consistent loss. The lowest rate, 0.001, produced a peak accuracy of 19.14% with slow, steady reduction in loss over epochs, showing stable but gradual progress. Higher learning rates accelerated convergence due to updates in only the final layer."
      ],
      "metadata": {
        "id": "NcTI3ky4bAXS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Yz0oul-bQQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "full finetuning yielded a much higher final accuracy (~59%) compared to feature extraction (where the best accuracy reached around 19.53%) across all tested learning rates. The winning approach was full finetuning with a learning rate of 0.01, which showed strong performance, achieving the highest validation accuracy due to the model adjusting weights in all layers.\n",
        "\n",
        "The main reason full finetuning outperformed feature extraction is that updating all layers allows the model to adapt more to the nuances of the new dataset, especially when the target dataset is distinct from the source dataset (ImageNet). By freezing most of the layers, feature extraction restricts adaptation, resulting in lower accuracy as it relies only on adjustments to the final layer. Full finetuning takes advantage of all layers’ ability to learn dataset-specific features."
      ],
      "metadata": {
        "id": "MdMub-TbEspl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZtYJt3gFqI0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}